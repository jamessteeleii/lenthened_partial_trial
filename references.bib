@article{abtPowerPrecisionSample2020,
  title = {Power, Precision, and Sample Size Estimation in Sport and Exercise Science Research},
  author = {Abt, Grant and Boreham, Colin and Davison, Gareth and Jackson, Robin and Nevill, Alan and Wallace, Eric and Williams, Mark},
  year = {2020},
  month = sep,
  journal = {Journal of Sports Sciences},
  volume = {38},
  number = {17},
  pages = {1933--1935},
  publisher = {Routledge},
  issn = {0264-0414},
  doi = {10.1080/02640414.2020.1776002},
  urldate = {2024-12-01},
  pmid = {32558628},
  file = {C:\Users\james\Zotero\storage\Y858DX8B\Abt et al. - 2020 - Power, precision, and sample size estimation in sport and exercise science research.pdf}
}

@misc{kurzJustUseMultilevel2022,
  title = {Just Use Multilevel Models for Your Pre/Post {{RCT}} Data},
  author = {Kurz, A. Solomon},
  year = {2022},
  month = jun,
  journal = {A. Solomon Kurz},
  urldate = {2024-12-02},
  abstract = {I've been thinking a lot about how to analyze pre/post control group designs, lately. Happily, others have thought a lot about this topic, too. The goal of this post is to introduce the change-score and ANCOVA models, introduce their multilevel-model counterparts, and compare their behavior in a couple quick simulation studies. Spoiler alert: The multilevel variant of the ANCOVA model is the winner.},
  langid = {english},
  file = {C:\Users\james\Zotero\storage\IDV67UZM\2022-06-13-just-use-multilevel-models-for-your-pre-post-rct-data.html}
}

@misc{lakensImprovingYourStatistical2022a,
  title = {Improving {{Your Statistical Inferences}}},
  author = {Lakens, Dani{\"e}l},
  year = {2022},
  month = apr,
  doi = {10.5281/ZENODO.6409077},
  urldate = {2024-12-01},
  abstract = {This open educational resource contains information to improve statistical inferences, design better experiments, and report scientific research more transparently.},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International, Open Access},
  howpublished = {Zenodo},
  keywords = {experimental design,frequentist statistics,hypothesis testing,open science,statistical inferences}
}

@article{mesquidaPublicationBiasStatistical2023,
  title = {Publication Bias, Statistical Power and Reporting Practices in the {{Journal}} of {{Sports Sciences}}: Potential Barriers to Replicability},
  shorttitle = {Publication Bias, Statistical Power and Reporting Practices in the {{Journal}} of {{Sports Sciences}}},
  author = {Mesquida, Cristian and Murphy, Jennifer and Lakens, Dani{\"e}l and Warne, Joe},
  year = {2023},
  month = aug,
  journal = {Journal of Sports Sciences},
  volume = {41},
  number = {16},
  pages = {1507--1517},
  publisher = {Routledge},
  issn = {0264-0414},
  doi = {10.1080/02640414.2023.2269357},
  urldate = {2024-12-01},
  abstract = {Two factors that decrease the replicability of studies in the scientific literature are publication bias and studies with underpowered desgins. One way to ensure that studies have adequate statistical power to detect the effect size of interest is by conducting a-priori power analyses. Yet, a previous editorial published in the Journal of Sports Sciences reported a median sample size of 19 and the scarce usage of a-priori power analyses. We meta-analysed 89 studies from the same journal to assess the presence and extent of publication bias, as well as the average statistical power, by conducting a z-curve analysis. In a larger sample of 174 studies, we also examined a) the usage, reporting practices and reproducibility of a-priori power analyses; and b) the prevalence of reporting practices of t-statistic or F-ratio, degrees of freedom, exact p-values, effect sizes and confidence intervals. Our results indicate that there was some indication of publication bias and the average observed power was low (53\% for significant and non-significant findings and 61\% for only significant findings). Finally, the usage and reporting practices of a-priori power analyses as well as statistical results including test statistics, effect sizes and confidence intervals were suboptimal.},
  pmid = {38018365},
  keywords = {publication bias,Replicability,reporting practices,reproducibility,statistical power},
  file = {C:\Users\james\Zotero\storage\JK2H3VUF\Mesquida et al. - 2023 - Publication bias, statistical power and reporting practices in the Journal of Sports Sciences poten.pdf}
}

@article{penneyCautionsWhenNormalizing2023,
  title = {Cautions When Normalizing the Dependent Variable in a Regression as a Z-Score},
  author = {Penney, Jeffrey},
  year = {2023},
  journal = {Economic Inquiry},
  volume = {61},
  number = {2},
  pages = {402--412},
  issn = {1465-7295},
  doi = {10.1111/ecin.13127},
  urldate = {2024-11-29},
  abstract = {It is common in empirical analysis to facilitate inference by transforming the dependent variable to follow a standard normal distribution. In this paper, I show that using this transformation results in the estimated treatment effects being systematically attenuated toward zero and bounded in magnitude. The level of attenuation can be empirically relevant. I propose an alternative normalization wherein the dependent variable is divided by the square root of its within variation, which corrects these issues. I show that, in a simple linear regression, the method produces an estimated treatment effect that is numerically identical to Cohen's d.},
  copyright = {{\copyright} 2022 Western Economic Association International.},
  langid = {english},
  keywords = {bounds,Cohen's d,effect size,normalization,standard scores,z-scores},
  file = {C:\Users\james\Zotero\storage\KG54P3M7\ecin.html}
}

@misc{rodriguez-sanchezGratefulFacilitateCitation2023,
  title = {Grateful: {{Facilitate Citation}} of {{R Packages}}},
  shorttitle = {Grateful},
  author = {{Rodriguez-Sanchez}, Francisco and {cre} and {cph} and Jackson, Connor P. and Hutchins, Shaurita D. and Clawson, James M.},
  year = {2023},
  month = oct,
  urldate = {2024-07-10},
  abstract = {Facilitates the citation of R packages used in analysis projects. Scans project for packages used, gets their citations, and produces a document with citations in the preferred bibliography format, ready to be pasted into reports or manuscripts. Alternatively, 'grateful' can be used directly within an 'R Markdown' or 'Quarto' document.},
  copyright = {MIT + file LICENSE}
}

@article{steeleMetaanalysisVariationSport2023,
  title = {Meta-Analysis of Variation in Sport and Exercise Science: {{Examples}} of Application within Resistance Training Research},
  shorttitle = {Meta-Analysis of Variation in Sport and Exercise Science},
  author = {Steele, James and Fisher, James P. and Smith, Dave and Schoenfeld, Brad J. and Yang, Yefeng and Nakagawa, Shinichi},
  year = {2023},
  month = sep,
  journal = {Journal of Sports Sciences},
  volume = {41},
  number = {17},
  pages = {1617--1634},
  publisher = {Routledge},
  issn = {0264-0414},
  doi = {10.1080/02640414.2023.2286748},
  urldate = {2024-02-22},
  abstract = {Meta-analysis has become commonplace within sport and exercise science for synthesising and summarising empirical studies. However, most research in the field focuses upon mean effects, particularly the effects of interventions to improve outcomes such as fitness or performance. It is thought that individual responses to interventions vary considerably. Hence, interest has increased in exploring precision or personalised exercise approaches. Not only is the mean often affected by interventions, but variation may also be impacted. Exploration of variation in studies such as randomised controlled trials (RCTs) can yield insight into interindividual heterogeneity in response to interventions and help determine generalisability of effects. Yet, larger samples sizes than those used for typical mean effects are required when probing variation. Thus, in a field with small samples such as sport and exercise science, exploration of variation through a meta-analytic framework is appealing. Despite the value of embracing and exploring variation alongside mean effects in sport and exercise science, it is rarely applied to research synthesis through meta-analysis. We introduce and evaluate different effect size calculations along with models for meta-analysis of variation using relatable examples from resistance training RCTs.},
  pmid = {38037792},
  keywords = {effect size,individual response,intervention,Meta-analysis,variability}
}

@misc{swintonAdequateStatisticalPower2024,
  title = {Adequate Statistical Power in Strength and Conditioning May Be Achieved through Longer Interventions and High Frequency Outcome Measurement.},
  author = {Swinton, Paul},
  year = {2024},
  month = jan,
  publisher = {SportRxiv},
  doi = {10.51224/SRXIV.364},
  urldate = {2024-12-01},
  archiveprefix = {SportRxiv},
  langid = {english},
  keywords = {Linear mixed models,Measurement error,Sample size,Statistics},
  file = {C:\Users\james\Zotero\storage\XJ7DVBXC\Swinton - 2024 - Adequate statistical power in strength and conditioning may be achieved through longer interventions.pdf}
}

@misc{varovicRegionalHypertrophyResistance2024,
  title = {Regional {{Hypertrophy}} with {{Resistance Training}}---{{Does Muscle Length Matter}}? {{A Systematic Review}} and {{Meta-Analysis}}},
  shorttitle = {Regional {{Hypertrophy}} with {{Resistance Training}}---{{Does Muscle Length Matter}}?},
  author = {Varovic, Dorian and Wolf, Milo and Steele, James and Schoenfeld, Brad J. and Grgic, Jozo and Mikulic, Pavle},
  year = {2024},
  month = oct,
  publisher = {SportRxiv},
  doi = {10.51224/SRXIV.464},
  urldate = {2024-11-26},
  archiveprefix = {SportRxiv},
  langid = {english},
  keywords = {muscle hypertrophy,muscle length,range of motion,resistance training},
  file = {C:\Users\james\Zotero\storage\S3VWFNMQ\Varovic et al. - 2024 - Regional Hypertrophy with Resistance Trainingâ€”Does Muscle Length Matter A Systematic Review and Met.pdf}
}
